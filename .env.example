# PROJECT LUMEN - Environment Configuration Example
# Copy this file to .env and fill in your values

# Application Settings
APP_NAME=PROJECT LUMEN
DEBUG=True

# API Settings
API_HOST=0.0.0.0
API_PORT=8000

# LLM Configuration
LLM_PROVIDER=openai
# Options: openai, anthropic, local

LLM_MODEL=gpt-3.5-turbo
# OpenAI models: gpt-3.5-turbo, gpt-4
# For local: specify model path

# OpenAI API Key (if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here

# LLM Parameters
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=1000

# RAG Configuration
EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
RERANKER_MODEL=castorini/monot5-base-msmarco

CHUNK_SIZE=500
CHUNK_OVERLAP=50

DENSE_TOP_K=50
SPARSE_TOP_K=30
RERANK_TOP_K=5

# Agent Configuration
AUDIT_THRESHOLD=0.15
FRAUD_ZSCORE_THRESHOLD=3.0
COMPLIANCE_CONFIDENCE=0.7

# Upload Settings
MAX_UPLOAD_SIZE=10485760
# 10MB in bytes

# Logging
LOG_LEVEL=INFO
