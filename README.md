# PROJECT LUMEN ğŸ”†

**AI-Native Financial Intelligence Layer**

An autonomous AI system that transforms raw financial documents into structured intelligence through multimodal analysis, RAG-powered reasoning, and agentic audit workflows.

---

## ğŸ¯ Overview

Project LUMEN is an end-to-end AI financial intelligence platform that:

- **Ingests** financial documents (PDFs, images) and extracts structured data
- **Indexes** content using hybrid RAG (Dense + Sparse + HyDE retrieval)
- **Analyzes** invoices with autonomous AI agents (Audit, Compliance, Fraud, Explainability)
- **Maintains** persistent memory in `workspace.md` for context-aware reasoning
- **Delivers** actionable insights through a clean web interface

---

## ğŸ—ï¸ Architecture

### Technology Stack

| Component | Technology |
|-----------|-----------|
| **Backend** | Python FastAPI |
| **Embeddings** | sentence-transformers/all-mpnet-base-v2 |
| **Vector Store** | FAISS (local) |
| **Sparse Retrieval** | BM25 (rank-bm25) |
| **Reranker** | MonoT5 (castorini/monot5-base-msmarco) |
| **Document Processing** | pdfminer.six, pytesseract |
| **Anomaly Detection** | IsolationForest, Z-score |
| **Frontend** | HTML/CSS/JavaScript |

### Core Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DOCUMENT INGESTION                    â”‚
â”‚  PDF/Image â†’ Text Extraction â†’ LLM Parsing â†’ Indexing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   RAG PIPELINE (Local)                  â”‚
â”‚  HyDE â†’ Dense (FAISS) + Sparse (BM25) â†’ Rerank (MonoT5)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AGENTIC AI SYSTEM                     â”‚
â”‚  Audit Agent â†’ Compliance Agent â†’ Fraud Agent â†’        â”‚
â”‚  Explainability Agent â†’ workspace.md                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.9+**
2. **Tesseract OCR** (for image processing)
   - Windows: Download from [GitHub](https://github.com/UB-Mannheim/tesseract/wiki)
   - Mac: `brew install tesseract`
   - Linux: `sudo apt-get install tesseract-ocr`
3. **OpenAI API Key** (optional, for LLM parsing)

### Installation

```bash
# Clone repository
cd project-lumen

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Configuration

Create a `.env` file in the root directory:

```env
# LLM Configuration (Optional)
LLM_PROVIDER=openai
LLM_MODEL=gpt-3.5-turbo
OPENAI_API_KEY=your_api_key_here

# Or use local models
# LLM_PROVIDER=local
```

### Run the Application

#### Backend

```bash
# From project root
cd backend
python main.py

# Or using uvicorn directly
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```

Backend will be available at: `http://localhost:8000`

API Documentation: `http://localhost:8000/docs`

#### Frontend

```bash
# Open frontend/index.html in a browser
# Or use a simple HTTP server:
cd frontend
python -m http.server 3000

# Then open: http://localhost:3000
```

---

## ğŸ“¡ API Endpoints

### 1. Document Ingestion

**POST** `/ingest/`

Upload and process financial documents.

```bash
curl -X POST "http://localhost:8000/ingest/" \
  -F "file=@invoice.pdf"
```

**Response:**
```json
{
  "status": "success",
  "document_id": "doc_abc123",
  "filename": "invoice.pdf",
  "extracted_fields": {
    "vendor": "ABC Corp",
    "date": "2025-11-10",
    "amount": 1250.00,
    "tax": 225.00,
    "category": "Office Supplies",
    "invoice_number": "INV-001"
  },
  "chunks_created": 12
}
```

### 2. Audit Execution

**POST** `/audit/`

Run comprehensive multi-agent audit.

```bash
curl -X POST "http://localhost:8000/audit/" \
  -H "Content-Type: application/json" \
  -d '{
    "invoice_data": {
      "vendor": "ABC Corp",
      "date": "2025-11-10",
      "amount": 1250.00,
      "tax": 225.00,
      "category": "Office Supplies",
      "invoice_number": "INV-001"
    }
  }'
```

**Response:**
```json
{
  "audit_id": "audit_xyz789",
  "overall_status": "pass",
  "findings": {
    "audit": {
      "status": "pass",
      "duplicates": [],
      "mismatches": [],
      "total_errors": []
    },
    "compliance": {
      "compliant": true,
      "violations": [],
      "confidence": 0.85
    },
    "fraud": {
      "anomaly_detected": false,
      "risk_score": 0.23,
      "suspicious_indicators": []
    }
  },
  "explanation": "Detailed natural language summary..."
}
```

### 3. Workspace Memory

**GET** `/memory/`

Retrieve complete workspace memory.

```bash
curl "http://localhost:8000/memory/"
```

**GET** `/memory/recent?n=10`

Get recent entries.

**POST** `/memory/search`

Search workspace content.

---

## ğŸ§  Agentic AI System

### 1. **Audit Agent**
- Detects duplicate invoices
- Analyzes vendor spending patterns
- Verifies invoice totals and calculations
- Identifies amount anomalies

### 2. **Compliance Agent**
- Retrieves relevant policies using RAG
- Validates invoices against financial rules
- Checks approval requirements
- Ensures regulatory compliance

### 3. **Fraud Agent**
- Z-score anomaly detection
- Isolation Forest ML model
- Pattern-based fraud indicators
- Risk scoring (0-1 scale)

### 4. **Explainability Agent**
- Generates natural language summaries
- Contextualizes findings
- Provides actionable recommendations
- Transparent decision-making

---

## ğŸ” RAG Pipeline Details

### Hybrid Retrieval Flow

1. **HyDE (Hypothetical Document Embeddings)**
   - LLM generates hypothetical policy document
   - Improves query quality for dense retrieval

2. **Dense Retrieval**
   - Sentence-transformers embeddings
   - FAISS vector similarity search
   - Top 50 chunks retrieved

3. **Sparse Retrieval**
   - BM25 lexical matching
   - Complementary keyword search
   - Top 30 chunks retrieved

4. **Merge & Deduplicate**
   - Combine dense + sparse results
   - Remove duplicates by content

5. **Rerank with MonoT5**
   - Cross-encoder relevance scoring
   - Return top 5 most relevant chunks

---

## ğŸ“‚ Project Structure

```
project-lumen/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                      # FastAPI app entry
â”‚   â”œâ”€â”€ config.py                    # Configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ ingest.py               # Ingestion API
â”‚   â”‚   â”œâ”€â”€ audit.py                # Audit API
â”‚   â”‚   â””â”€â”€ memory.py               # Memory API
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ vector_store.py         # FAISS operations
â”‚   â”‚   â”œâ”€â”€ sparse_retriever.py     # BM25 retrieval
â”‚   â”‚   â”œâ”€â”€ hyde.py                 # HyDE generation
â”‚   â”‚   â”œâ”€â”€ reranker.py             # MonoT5 reranking
â”‚   â”‚   â”œâ”€â”€ retriever.py            # Hybrid orchestration
â”‚   â”‚   â””â”€â”€ chunker.py              # Text chunking
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ audit_agent.py          # Audit logic
â”‚   â”‚   â”œâ”€â”€ compliance_agent.py     # Compliance validation
â”‚   â”‚   â”œâ”€â”€ fraud_agent.py          # Fraud detection
â”‚   â”‚   â”œâ”€â”€ explainability_agent.py # Explanation generation
â”‚   â”‚   â””â”€â”€ orchestrator.py         # Agent coordination
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ text_extract.py         # PDF/Image extraction
â”‚   â”‚   â”œâ”€â”€ llm_parser.py           # LLM-based parsing
â”‚   â”‚   â”œâ”€â”€ workspace_writer.py     # workspace.md manager
â”‚   â”‚   â””â”€â”€ logger.py               # Logging
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ vector_index.faiss      # FAISS index
â”‚   â”‚   â”œâ”€â”€ chunks.jsonl            # Indexed chunks
â”‚   â”‚   â”œâ”€â”€ bm25_index/             # BM25 index files
â”‚   â”‚   â”œâ”€â”€ uploads/                # Uploaded files
â”‚   â”‚   â””â”€â”€ policy_docs/            # Policy documents
â”‚   â”‚
â”‚   â””â”€â”€ workspace.md                # Persistent memory
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html                  # Main UI
â”‚   â”œâ”€â”€ app.js                      # Application logic
â”‚   â””â”€â”€ styles.css                  # Styling
â”‚
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ PROJECT_OUTLINE.md              # Architecture docs
â””â”€â”€ DEVELOPMENT_LOG.md              # Development log
```

---

## ğŸ¨ Frontend Features

### 1. Document Ingestion Panel
- Drag & drop file upload
- Real-time extraction results
- Auto-populate audit form

### 2. Audit Execution Panel
- Manual invoice entry
- Full multi-agent audit
- Detailed findings display

### 3. Workspace Memory Viewer
- Recent activity feed
- Full workspace view
- Statistics dashboard

---

## ğŸ§ª Testing

### Test Document Ingestion

```bash
# Test with sample invoice
curl -X POST "http://localhost:8000/ingest/" \
  -F "file=@sample_invoice.pdf"
```

### Test Audit

```bash
# Test audit endpoint
curl -X POST "http://localhost:8000/audit/" \
  -H "Content-Type: application/json" \
  -d '{
    "invoice_data": {
      "vendor": "Test Vendor",
      "date": "2025-11-13",
      "amount": 500.00,
      "tax": 50.00,
      "category": "Office Supplies"
    }
  }'
```

### Health Check

```bash
curl "http://localhost:8000/health"
```

---

## ğŸ” Security Features

- End-to-end local processing (no external APIs for RAG)
- Audit trail in workspace.md
- File size limits on uploads
- Input validation and sanitization
- CORS configuration for frontend

---

## ğŸ“Š Performance

| Operation | Typical Time |
|-----------|--------------|
| PDF Text Extraction | 1-3s |
| Image OCR | 2-5s |
| LLM Parsing | 2-4s |
| Indexing (per doc) | 1-2s |
| Hybrid Retrieval | 0.5-1s |
| Full Audit | 5-10s |

---

## ğŸš§ Known Limitations

1. **LLM Dependency**: Document parsing and HyDE require LLM (OpenAI API or local model)
2. **Tesseract OCR**: Image quality affects OCR accuracy
3. **Memory Usage**: Large document sets may require RAM optimization
4. **MonoT5 Reranking**: Can be slow without GPU acceleration

---

## ğŸ”® Future Enhancements

- [ ] Local LLM support (Llama 2, Mistral)
- [ ] Multi-language support
- [ ] Blockchain-based audit trails
- [ ] Smart purchase reminders
- [ ] Category-based spending forecasts
- [ ] Real-time anomaly alerts
- [ ] Multi-user authentication
- [ ] ERP system integrations

---

## ğŸ› ï¸ Troubleshooting

### Issue: Tesseract not found

**Solution:**
```bash
# Windows: Add Tesseract to PATH
# Or set in config.py:
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
```

### Issue: CUDA out of memory

**Solution:**
```bash
# Use CPU-only versions
pip uninstall torch
pip install torch --index-url https://download.pytorch.org/whl/cpu
```

### Issue: OpenAI API errors

**Solution:**
- Check API key in .env file
- Verify sufficient credits
- Or set `LLM_PROVIDER=local` for rule-based fallback

---

## ğŸ“– Documentation

- **API Docs**: http://localhost:8000/docs
- **Project Outline**: See `PROJECT_OUTLINE.md`
- **Development Log**: See `DEVELOPMENT_LOG.md`

---

## ğŸ¤ Contributing

This is a hackathon project built for **PROJECT LUMEN** challenge.

Key areas for contribution:
- Additional fraud detection algorithms
- More compliance policy templates
- Enhanced OCR preprocessing
- Performance optimizations

---

## ğŸ“„ License

MIT License - Built for educational and research purposes.

---

## ğŸ† Hackathon Submission

**Project**: PROJECT LUMEN - AI Financial Intelligence Layer

**Theme**: Generative AI | Agentic AI | Financial Security

**Key Innovations**:
1. âœ… Multimodal document intelligence (PDF + Image)
2. âœ… Hybrid RAG with HyDE enhancement
3. âœ… Multi-agent autonomous reasoning
4. âœ… Explainable AI with natural language summaries
5. âœ… Persistent workspace memory for context
6. âœ… Local-first architecture (privacy-preserving)

---

## ğŸ‘¥ Team

Built with â¤ï¸ by the Project LUMEN Team

---

## ğŸ“ Support

For issues or questions:
- Check the `/health` endpoint
- Review logs in `backend/lumen.log`
- Inspect `workspace.md` for audit history

---

**PROJECT LUMEN** - Illuminating Financial Intelligence Through AI ğŸ”†
